# Risk Profile: Story 2.3 - Automatic Column Detection

**Date:** 2025-10-15
**Reviewer:** Quinn (Test Architect)
**Story ID:** 2.3
**Story Title:** Automatic Column Detection

---

## Executive Summary

- **Total Risks Identified:** 12
- **Critical Risks (Score 9):** 1
- **High Risks (Score 6):** 3
- **Medium Risks (Score 4):** 5
- **Low Risks (Score 2-3):** 3
- **Overall Risk Score:** 53/100 (Moderate-High Risk)

**Key Finding:** The column detection algorithm represents the core feature with significant accuracy and usability risks. The 90% accuracy requirement combined with diverse CSV format variations creates material technical and business risk.

---

## Critical Risks Requiring Immediate Attention

### 1. [TECH-001] Column Detection Accuracy Below 90% Target

**Score: 9 (Critical)**
**Probability:** High (3) - Complex pattern matching across 12+ format variations with limited validation testing
**Impact:** High (3) - Failure to meet AC6 blocks story completion; poor auto-detection forces manual mapping, degrading UX significantly

**Detailed Analysis:**

The detection algorithm must correctly identify date, amount, description, and memo columns across 12 diverse CSV samples (4 standard, 4 edge cases, 4 malformed). Key challenges:

- **Date Format Ambiguity:** 3 date formats (MM/DD/YYYY, YYYY-MM-DD, DD.MM.YYYY) with non-zero-padded variants (M/D/YYYY)
- **Multi-Language Headers:** German ("Datum", "Betrag", "Beschreibung"), Spanish ("Fecha", "Monto") require fuzzy matching
- **Amount Column Split:** 42% of samples use Debit/Credit split vs. single Amount column
- **Parentheses Negatives:** 25% of samples use `(50.00)` format instead of `-50.00`
- **European Number Format:** 17% use comma decimal separator (1.234,56) vs. period (1,234.56)

**Mitigation:**

1. **Preventive:**
   - Implement comprehensive pattern matching using `column-name-mapping.json` reference data
   - Use data validation (parse sample rows to confirm detected type)
   - Implement confidence scoring with 0.7 threshold for required fields
   - Add fallback hierarchy: exact match → fuzzy match → data pattern analysis

2. **Testing Requirements:**
   - Unit test each detection method (date, amount, description, memo) independently
   - Integration test all 12 CSV samples from Story 2.1
   - Validate ≥90% success rate for standard (4/4) and edge case (4/4) samples
   - Document detection failures with root cause analysis

3. **Residual Risk:** Medium - Novel CSV formats not in test samples may still fail detection

**Testing Focus:**
- Test all 12 samples end-to-end with detection service
- Negative testing: intentionally ambiguous headers (e.g., "Value" could be amount or balance)
- Edge case: CSV with no headers (no-headers.csv sample)
- Performance test: detection time <100ms per file

**Owner:** Dev team
**Timeline:** Must fix before Story 2.3 completion (blocks AC6)

---

## High Risks (Score 6)

### 2. [DATA-001] Incorrect Column Mapping Causes Data Corruption

**Score: 6 (High)**
**Probability:** Medium (2) - Confidence scoring should catch most errors, but edge cases remain
**Impact:** High (3) - Misidentified amount/date columns could corrupt user's financial records

**Scenario:**

User uploads CSV with ambiguous headers:
```csv
Date,Details,Value,Balance
01/15/2025,Purchase,100.00,1234.56
```

Algorithm incorrectly maps:
- "Value" → Description (should be Amount)
- "Details" → Amount (should be Description)

Result: Transactions created with description field containing numeric values, amounts containing text → database constraint violations or semantic data corruption.

**Mitigation:**

1. **Preventive:**
   - Implement `ColumnMappingValidator.cs` with FluentValidation
   - Validate required fields detected (date AND amount mandatory)
   - Data validation: parse sample rows to confirm type (amounts must parse as decimal)
   - Return validation warnings if confidence <0.7

2. **Detective:**
   - Display confidence indicators in UI (green checkmark >0.9, yellow warning 0.7-0.9, red alert <0.7)
   - Warning banner: "Column detection needs review" when confidence <0.7
   - Disable "Next" button if required fields not detected with >0.7 confidence

3. **Corrective:**
   - Manual mapping UI (Story 2.4) allows user to override auto-detection
   - Graceful degradation: low confidence → show mapping interface

**Testing Focus:**
- Test ambiguous header scenarios (e.g., "Value", "Total", "Number")
- Verify validation blocks proceed when confidence <0.7
- Verify warning banners display correctly in UI

**Owner:** Dev team
**Timeline:** Before Story 2.3 completion

---

### 3. [PERF-001] Detection Algorithm Timeout on Large CSV Files

**Score: 6 (High)**
**Probability:** Medium (2) - Algorithm analyzes headers + 10 sample rows; pattern matching may be slow
**Impact:** High (3) - Detection exceeding 100ms target contributes to >2s total parsing time, degrading UX

**Analysis:**

Detection algorithm time complexity:
- **Header Matching:** O(headers × patterns) = O(10 × 50) = 500 substring comparisons
- **Data Validation:** O(headers × sample_rows × patterns) = O(10 × 10 × 50) = 5,000 operations
- **Regex Parsing:** Date validation requires `DateTime.TryParseExact()` for 3 formats per cell

Without optimization, detection could take 200-500ms per file.

**Mitigation:**

1. **Preventive:**
   - Pre-compile regex patterns at service initialization (singleton pattern)
   - Pre-load `column-name-mapping.json` on startup (not per request)
   - Short-circuit validation: stop after first 3 rows validate successfully
   - Cache detection results by file hash (if same file uploaded multiple times)

2. **Testing Requirements:**
   - Performance test with 1,000-row CSV file (target: <100ms detection time)
   - Profile algorithm with dotnet-trace to identify bottlenecks
   - Load test: 100 concurrent requests

**Testing Focus:**
- Measure detection time independently from CSV parsing
- Test with largest sample file from Story 2.1 collection
- Verify detection time <10% of total preview endpoint response time

**Owner:** Dev team
**Timeline:** Before Story 2.3 completion

---

### 4. [BUS-001] Poor Auto-Detection UX Damages User Trust

**Score: 6 (High)**
**Probability:** High (3) - If accuracy <90%, users encounter mapping failures frequently
**Impact:** Medium (2) - Users lose confidence in app; may abandon CSV import feature

**Scenario:**

User uploads bank CSV. Detection identifies:
- Date column: ❌ Low confidence (0.65)
- Amount column: ✅ High confidence (0.95)
- Description: ❌ Not detected

User sees red warning banner: "Column detection needs review."

**If Story 2.4 (manual mapping) not yet implemented:** User is blocked. "Next" button disabled. No way to proceed.

**Mitigation:**

1. **Preventive:**
   - Achieve ≥90% detection accuracy to minimize failures
   - Display helpful error messages: "Please review column mapping before proceeding"
   - Add tooltip showing confidence scores on hover (educational)

2. **Detective:**
   - Track detection success rate via telemetry (log confidence scores)
   - Alert if success rate <85% in production

3. **Corrective:**
   - Story 2.4 manual mapping UI provides escape hatch
   - Consider "Skip auto-detection" checkbox for advanced users

**Testing Focus:**
- User acceptance testing with real-world CSV files (not just test samples)
- Verify helpful messaging when detection fails
- Test tooltip and confidence indicator rendering

**Owner:** Dev team + UX
**Timeline:** Before Story 2.3 completion

---

## Medium Risks (Score 4)

### 5. [TECH-002] Multi-Line Memo Field Detection Failure

**Score: 4 (Medium)**
**Probability:** Medium (2) - 1/12 samples contains multi-line memos; edge case but documented
**Impact:** Medium (2) - Detection may misidentify memo column due to newline characters

**Example:**
```csv
Date,Payee,Amount,Memo
2025-01-15,ACME Corp,1500.00,"Invoice #12345
Payment for consulting
January 2025"
```

CsvHelper parses correctly, but detection algorithm may count memo as 3 columns instead of 1.

**Mitigation:**
- CsvHelper handles quoted multi-line fields correctly
- Test with `multiline-memo.csv` sample
- Verify detection analyzes parsed columns (not raw text)

---

### 6. [TECH-003] No Header Row Detection Fails

**Score: 4 (Medium)**
**Probability:** Medium (2) - 8% of samples (1/12) lack headers
**Impact:** Medium (2) - Algorithm must infer column types from data patterns; failure rate higher

**Example (no-headers.csv):**
```csv
2025-01-20,Coffee Shop,-5.75,1250.00
2025-01-18,Gas Station,-45.00,1255.75
```

Detection must:
1. Recognize row 1 is NOT headers (contains date/amount data)
2. Infer column types: position 0 = date, position 2 = amount, position 1 = description, position 3 = balance

**Mitigation:**
- Implement header detection logic: check if row 1 contains "date", "amount", etc.
- If no headers found, analyze data patterns in row 1
- Test with `no-headers.csv` sample
- Document as known limitation if detection fails (defer to manual mapping)

---

### 7. [DATA-002] European Number Format (Comma Decimal) Misidentified

**Score: 4 (Medium)**
**Probability:** Medium (2) - 17% of samples use European format (2/12)
**Impact:** Medium (2) - Amount column detection may fail or parse amounts incorrectly

**Example:**
```csv
Datum;Beschreibung;Betrag;Saldo
15.01.2025;Einkauf;-1.234,56;5.678,90
```

Amount: `-1.234,56` (European: -1234.56) vs. US interpretation: `-1.234` (incorrect)

**Mitigation:**
- Analyze delimiter patterns: if `,` appears once at end → European decimal
- Test with European samples (2 from Story 2.1 collection)
- Document in Dev Notes that European format requires semicolon delimiter

---

### 8. [SEC-001] CSV Content Logged Exposes User Financial Data

**Score: 4 (Medium)**
**Probability:** Medium (2) - Developers may log detection results including sample rows for debugging
**Impact:** Medium (2) - Privacy violation; user financial transactions exposed in logs

**Mitigation:**
- **CRITICAL RULE:** Log only metadata (header names, field types, confidence scores)
- **NEVER log CSV content** (sample rows contain sensitive payee/amount data)
- Add code review checklist item: "Verify no PII logged in ColumnDetectionService"
- Use Serilog structured logging: `Log.Information("Detection completed: DateConfidence={Confidence}", dateConfidence)`

**Testing Focus:**
- Review all log statements in ColumnDetectionService
- Verify no `sampleRows` variable logged
- Test log output in staging environment

---

### 9. [OPS-001] Detection Service Failure Blocks CSV Preview

**Score: 4 (Medium)**
**Probability:** Medium (2) - New service may throw exceptions on edge cases
**Impact:** Medium (2) - User cannot preview CSV; entire import workflow blocked

**Scenario:**

User uploads CSV. `PreviewCsvHandler` calls `ColumnDetectionService.DetectColumns()`. Service throws `NullReferenceException` on malformed data.

Exception propagates → API returns 500 error → User sees "Upload failed" message.

**Mitigation:**
1. **Preventive:**
   - Graceful error handling: catch exceptions in detection service
   - Return empty `ColumnDetectionResult` with warnings instead of throwing
   - Validate inputs: ensure headers and sampleRows are not null/empty

2. **Detective:**
   - Log detection failures with correlation ID
   - Monitor error rate for detection service in Application Insights

3. **Corrective:**
   - Fallback: if detection fails, return preview WITHOUT detection results
   - User can still see CSV preview, proceed to manual mapping (Story 2.4)

**Testing Focus:**
- Test with all 4 malformed samples from Story 2.1
- Verify service returns graceful error (not exception)
- Verify user still sees CSV preview when detection fails

---

## Low Risks (Score 2-3)

### 10. [TECH-004] Confidence Scoring Inconsistency

**Score: 3 (Low)**
**Probability:** Low (1) - Scoring algorithm straightforward
**Impact:** High (3) - Inconsistent scores could cause false positives/negatives

**Mitigation:**
- Define deterministic scoring rules in Dev Notes
- Unit test confidence calculations (high >0.9, medium 0.7-0.9, low <0.7)
- Test boundary conditions (e.g., exactly 0.7 confidence)

---

### 11. [PERF-002] Column-Name-Mapping.json Load Time on Startup

**Score: 2 (Low)**
**Probability:** Low (1) - JSON file is small (~5KB)
**Impact:** Medium (2) - Adds ~50ms to service initialization

**Mitigation:**
- Load JSON on ColumnDetectionService initialization (singleton)
- Not a request-level concern; negligible impact

---

### 12. [OPS-002] Missing Integration Test for All 12 Samples

**Score: 2 (Low)**
**Probability:** Low (1) - Task explicitly requires integration test (AC6)
**Impact:** Medium (2) - Without comprehensive test, accuracy cannot be validated

**Mitigation:**
- Create integration test that uploads all 12 CSV samples
- Assert detection success rate ≥90% for standard/edge cases
- Document failures in test report

---

## Risk Distribution

### By Category

| Category | Total Risks | Critical | High | Medium | Low |
|----------|-------------|----------|------|--------|-----|
| Technical (TECH) | 5 | 1 | 0 | 4 | 0 |
| Data (DATA) | 2 | 0 | 1 | 1 | 0 |
| Performance (PERF) | 2 | 0 | 1 | 0 | 1 |
| Security (SEC) | 1 | 0 | 0 | 1 | 0 |
| Business (BUS) | 1 | 0 | 1 | 0 | 0 |
| Operational (OPS) | 2 | 0 | 0 | 1 | 1 |

**Key Insight:** Technical risks dominate (42%), primarily around detection algorithm accuracy and edge case handling.

### By Component

| Component | Total Risks | Critical | High | Medium | Low |
|-----------|-------------|----------|------|--------|-----|
| ColumnDetectionService (Backend) | 6 | 1 | 1 | 3 | 1 |
| Frontend UI (import-csv.component) | 2 | 0 | 1 | 0 | 1 |
| PreviewCsvHandler Integration | 2 | 0 | 1 | 1 | 0 |
| Data Validation | 2 | 0 | 1 | 1 | 0 |

**Key Insight:** Backend detection service carries majority of risk; frontend primarily UX concerns.

---

## Detailed Risk Register

| Risk ID | Title | Category | Score | Probability | Impact | Priority |
|---------|-------|----------|-------|-------------|--------|----------|
| TECH-001 | Detection accuracy <90% | Technical | 9 | High (3) | High (3) | Critical |
| DATA-001 | Incorrect column mapping | Data | 6 | Med (2) | High (3) | High |
| PERF-001 | Detection timeout | Performance | 6 | Med (2) | High (3) | High |
| BUS-001 | Poor UX damages trust | Business | 6 | High (3) | Med (2) | High |
| TECH-002 | Multi-line memo detection | Technical | 4 | Med (2) | Med (2) | Medium |
| TECH-003 | No header row detection | Technical | 4 | Med (2) | Med (2) | Medium |
| DATA-002 | European number format | Data | 4 | Med (2) | Med (2) | Medium |
| SEC-001 | CSV content logged | Security | 4 | Med (2) | Med (2) | Medium |
| OPS-001 | Detection service failure | Operational | 4 | Med (2) | Med (2) | Medium |
| TECH-004 | Confidence scoring inconsistency | Technical | 3 | Low (1) | High (3) | Low |
| PERF-002 | JSON load time | Performance | 2 | Low (1) | Med (2) | Low |
| OPS-002 | Missing integration test | Operational | 2 | Low (1) | Med (2) | Low |

---

## Risk-Based Testing Strategy

### Priority 1: Critical Risk Tests (MUST COMPLETE)

**Focus: Detection Accuracy (TECH-001, DATA-001)**

1. **Unit Tests (ColumnDetectionServiceTests.cs):**
   - Test date column detection for all 3 date formats (MM/DD/YYYY, YYYY-MM-DD, DD.MM.YYYY)
   - Test amount column detection (single amount vs. debit/credit split)
   - Test parentheses negative amounts `(50.00)` → `-50.00`
   - Test European decimal separator `1.234,56` → `1234.56`
   - Test description column with German/Spanish headers
   - Test memo column detection (secondary text field)
   - Test confidence scoring (high >0.9, medium 0.7-0.9, low <0.7)
   - **Target: 80% code coverage minimum**

2. **Integration Tests:**
   - Upload all 12 CSV samples from Story 2.1 (standard, edge cases, malformed)
   - Assert detection success rate ≥90% for standard (4/4) and edge cases (4/4)
   - Document failures with root cause analysis
   - Verify malformed CSVs return low confidence (expected behavior)
   - **Target: 8/8 standard+edge cases pass, 0/4 malformed expected to pass**

3. **Data Validation Tests:**
   - Test `ColumnMappingValidator` requires date and amount fields
   - Test validation warning when confidence <0.7
   - Test graceful handling when required fields missing

### Priority 2: High Risk Tests (PERF-001, BUS-001)

**Focus: Performance and UX**

1. **Performance Tests:**
   - Measure detection time for 1,000-row CSV file (target: <100ms)
   - Profile with dotnet-trace to identify bottlenecks
   - Load test: 100 concurrent preview requests
   - Verify pre-compiled regex and JSON caching

2. **Frontend UI Tests:**
   - Test confidence indicator rendering (green checkmark, yellow warning, red alert)
   - Test field type badge display on column headers
   - Test warning banner when confidence <0.7
   - Test "Next" button disabled when required fields not detected
   - Test tooltip displays confidence score on hover

### Priority 3: Medium/Low Risk Tests

**Focus: Edge Cases and Operational Concerns**

1. **Edge Case Tests:**
   - Multi-line memo field (multiline-memo.csv)
   - No header row (no-headers.csv)
   - European number format (semicolon delimiter samples)
   - Empty columns (Debit/Credit split with blank values)

2. **Operational Tests:**
   - Test detection service failure handling (malformed samples)
   - Verify preview succeeds even when detection fails
   - Review log statements (ensure no PII logged)
   - Test error messages are user-friendly

---

## Risk Acceptance Criteria

### Must Fix Before Production

1. **TECH-001 (Critical):** Detection accuracy must meet ≥90% for standard/edge case samples
2. **DATA-001 (High):** Validation must prevent incorrect mappings from proceeding
3. **SEC-001 (Medium):** All logging statements reviewed; no CSV content logged

### Can Deploy with Mitigation

1. **BUS-001 (High):** If accuracy <90%, acceptable IF Story 2.4 manual mapping available as fallback
2. **PERF-001 (High):** If detection time >100ms, acceptable IF total preview time <2s
3. **TECH-002/003 (Medium):** Edge case detection failures acceptable IF documented as known limitations

### Accepted Risks

1. **TECH-004 (Low):** Minor confidence scoring inconsistencies acceptable if within ±5% margin
2. **PERF-002 (Low):** JSON load time acceptable (negligible impact)
3. **Multi-language support beyond German:** Spanish/French headers not guaranteed in MVP (defer to Phase 2)

---

## Monitoring Requirements

### Post-Deployment Monitoring

**Performance Metrics (PERF-001):**
- Track P50, P95, P99 detection time via Application Insights
- Alert if P95 >150ms
- Track total preview endpoint response time

**Accuracy Metrics (TECH-001):**
- Log confidence scores for all detections (anonymized, no PII)
- Track percentage of uploads with low confidence (<0.7)
- Alert if low-confidence rate >15%

**Error Rates (OPS-001):**
- Monitor detection service exceptions
- Alert if error rate >1% of requests
- Track correlation IDs for failed detections

**Business KPIs (BUS-001):**
- Track CSV import completion rate (preview → final import)
- Monitor abandonment rate at preview stage
- Survey user satisfaction with auto-detection feature

---

## Risk Review Triggers

**Update risk profile when:**

1. New CSV format encountered in production (not in test samples)
2. Detection accuracy falls below 85% in telemetry
3. Performance degradation: P95 detection time >200ms
4. Security incident: CSV content found in logs
5. User feedback: frequent manual mapping overrides needed
6. Story 2.4 (manual mapping) completed (changes risk landscape)

---

## Recommendations Summary

### Development Focus

1. **Implement comprehensive test suite FIRST** (TDD approach)
2. **Prioritize detection accuracy** over performance optimization initially
3. **Use reference data** (`column-name-mapping.json`, `CSV_FORMAT_ANALYSIS.md`) extensively
4. **Add defensive programming:** validate all inputs, handle nulls gracefully

### Testing Priority

1. Run integration test against all 12 samples EARLY in development
2. Test edge cases (multi-line, no headers, European format) explicitly
3. Performance test before declaring story complete
4. Manual UAT with real-world CSV files (not just test samples)

### Deployment Strategy

1. **Phased rollout:** Enable auto-detection for 10% of users initially
2. **Monitor telemetry:** Track accuracy and performance metrics
3. **Feature flag:** Allow fallback to manual mapping if issues detected
4. **Rollback plan:** Disable auto-detection, force manual mapping if accuracy <80%

### Quality Gate Recommendation

**Based on risk profile (Score: 53/100):**

- **1 Critical risk (TECH-001)** → Recommend **CONCERNS** gate status
- Gate can upgrade to **PASS** when:
  - Integration test demonstrates ≥90% accuracy (8/8 standard+edge cases)
  - All unit tests pass with ≥80% coverage
  - Performance test confirms detection time <100ms
  - Security review confirms no PII logging

---

**End of Risk Profile**

*Generated by Quinn (Test Architect) - 2025-10-15*
